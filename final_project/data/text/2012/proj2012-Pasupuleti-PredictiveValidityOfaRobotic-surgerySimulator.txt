Anirudh	 Â Pasupuleti	 Â SUID:	 Â 05833435	 Â SCPD#:	 Â X120939	 Â 
Predictive	 Â Validity	 Â of	 Â a	 Â Robotic	 Â Surgery	 Â Simulator	 Â 
	 Â 
	 Â The	 Â primary	 Â  goal	 Â of	 Â  this	 Â project	 Â  is	 Â  to	 Â  answer	 Â  the	 Â question:	 Â does	 Â performance/training	 Â with	 Â 
	 Â 
this	 Â simulator	 Â transfer	 Â to	 Â improvements	 Â in	 Â clinical	 Â robotic-Â­â€surgery	 Â on	 Â real	 Â patients?	 Â 
Introduction	 Â 
Briefly,	 Â  the	 Â  role	 Â  of	 Â  surgical	 Â  simulation	 Â  is	 Â  to	 Â  train/evaluate	 Â  Residents	 Â  (medical	 Â  students)	 Â 
before	 Â  stepping	 Â  into	 Â  the	 Â  shoes	 Â  of	 Â  robotic-Â­â€surgeons.	 Â  So,	 Â  this	 Â  project	 Â  focuses	 Â  most	 Â  on	 Â 
evaluating	 Â  the	 Â  simulator	 Â  that	 Â  evaluates	 Â  doctors.	 Â  In	 Â  sense,	 Â  we	 Â  are	 Â  trying	 Â  to	 Â  predict	 Â  the	 Â 
validity	 Â  of	 Â  a	 Â  simulator	 Â  (given)	 Â  by	 Â  collecting	 Â  the	 Â  data	 Â  it	 Â  provides	 Â  after	 Â  a	 Â  group	 Â  of	 Â  experts	 Â 
(robotic-Â­â€surgery)	 Â  perform	 Â  on	 Â  it.	 Â  So	 Â  we	 Â  will	 Â  be	 Â  predicting	 Â  the	 Â  R-Â­â€score	 Â  (which	 Â  is	 Â  the	 Â 
governing	 Â  score	 Â  for	 Â  graduating	 Â  a	 Â  Resident	 Â  into	 Â  an	 Â  operation	 Â  theatre),	 Â  from	 Â  a	 Â  given	 Â 
collection	 Â of	 Â R-Â­â€scores,	 Â which	 Â is	 Â in	 Â turn	 Â dependent	 Â on	 Â a	 Â set	 Â of	 Â governing	 Â performance	 Â related	 Â 
metrics,	 Â e.g.	 Â Time	 Â taken,	 Â Camera	 Â Usage,	 Â Clutch	 Â Usage,	 Â Left	 Â pinches,	 Â Right	 Â pinches,	 Â Cauterizer	 Â 
Usage	 Â and	 Â etc.	 Â 
	 Â 
The	 Â  data	 Â  is	 Â  available	 Â  at	 Â  my	 Â  current	 Â  employerâ€™s	 Â  database.	 Â  I	 Â  work	 Â  for	 Â  Simulated	 Â  Surgical	 Â 
Systems.	 Â We	 Â build	 Â the	 Â RoSS	 Â (Robotic	 Â Surgery	 Â Simulator).	 Â It	 Â  is	 Â a	 Â start-Â­â€up	 Â company	 Â  in	 Â NY	 Â and	 Â 
this	 Â  simulator	 Â  is	 Â  designed	 Â  for	 Â  training	 Â  doctors	 Â  for	 Â  Intuitive	 Â  Surgicalâ€™s	 Â  Da	 Â  Vinci	 Â  Surgical	 Â 
Data	 Â and	 Â Features	 Â 
System.	 Â  So,	 Â  we	 Â  already	 Â  have	 Â  about	 Â  20	 Â  simulators	 Â  spread	 Â  around	 Â  USA	 Â  and	 Â  a	 Â  couple	 Â  in	 Â 
Europe.	 Â  So,	 Â  we	 Â  have	 Â  collected	 Â  a	 Â  huge	 Â  set	 Â  of	 Â  data	 Â  of	 Â  experts	 Â  practicing	 Â  on	 Â  it	 Â  and	 Â  teaching	 Â 
their	 Â residents	 Â using	 Â the	 Â RoSS.	 Â 
	 Â Features	 Â 
Examples	 Â 
Time	 Â taken	 Â (sec)	 Â 
100	 Â 
Camera	 Â Usage	 Â (count)	 Â 
12	 Â 
5	 Â 
Clutch	 Â Usage	 Â (count)	 Â 
Left	 Â grasps	 Â (count)	 Â 
7	 Â 
Right	 Â grasps	 Â (count)	 Â 
9	 Â 
1840	 Â 
Distance	 Â moved	 Â by	 Â left	 Â tool	 Â (mm)	 Â 
Distance	 Â moved	 Â by	 Â right	 Â tool	 Â (mm)	 Â 
2014	 Â 
	 Â I	 Â  have	 Â  spent	 Â  time	 Â  on	 Â  selecting	 Â  Features	 Â  and	 Â  generating	 Â  them.	 Â  This	 Â  helped	 Â  me	 Â  in	 Â 
consolidating	 Â the	 Â useful	 Â data	 Â from	 Â unwanted	 Â features.	 Â In	 Â our	 Â model,	 Â the	 Â predicting	 Â problem	 Â 
is	 Â  converted	 Â  into	 Â  multiclass	 Â  classification	 Â  problem.	 Â  We	 Â  will	 Â  NaÃ¯ve	 Â  Bayes	 Â  as	 Â  our	 Â  prototype	 Â 
model	 Â  initially	 Â  for	 Â  training	 Â  and	 Â  testing	 Â  data.	 Â  We	 Â  will	 Â  compare	 Â  the	 Â  performance	 Â  of	 Â  the	 Â 
technique	 Â  by	 Â  employing	 Â  another	 Â  technique,	 Â  the	 Â  Logistic	 Â  Regression,	 Â  and	 Â  then	 Â  will	 Â  try	 Â  to	 Â 
achieve	 Â the	 Â final	 Â feature	 Â and	 Â model.	 Â 
	 Â Sentiment	 Â Polarity	 Â 
Sentiment	 Â Score	 Â 
Examples	 Â 
Expert	 Â 
+2	 Â 
Strong	 Â Positive	 Â 
Weak	 Â Positive	 Â 
+1	 Â 
Challenger	 Â 

Neutral	 Â 
0	 Â 
Competitor	 Â 
Trainee	 Â 
-Â­â€1	 Â 
Weak	 Â Negative	 Â 
Novice	 Â 
-Â­â€2	 Â 
Strong	 Â Negative	 Â 
	 Â In	 Â our	 Â experiments,	 Â  the	 Â Time	 Â  taken	 Â  is	 Â  the	 Â  strongest	 Â  individual	 Â  indicator	 Â of	 Â a	 Â userâ€™s	 Â R-Â­â€Score.	 Â 
In	 Â the	 Â  final	 Â report,	 Â I	 Â will	 Â attach	 Â the	 Â plot	 Â  for	 Â the	 Â X-Â­â€Y	 Â scatter	 Â graph	 Â of	 Â Time	 Â taken	 Â and	 Â R-Â­â€Score,	 Â 
which	 Â helps	 Â us	 Â  in	 Â  finding	 Â  their	 Â correlation,	 Â hence	 Â using	 Â  it	 Â as	 Â  the	 Â baseline	 Â result.	 Â  In	 Â sense,	 Â all	 Â 
reasonable	 Â models	 Â should	 Â be	 Â able	 Â to	 Â achieve	 Â at	 Â least	 Â this	 Â correlation.	 Â 
	 Â 
In	 Â  our	 Â  first	 Â  model,	 Â  we	 Â  used	 Â  a	 Â  standard	 Â  least	 Â  gradient	 Â  descent,	 Â  which	 Â  we	 Â  implemented	 Â  in	 Â  C	 Â 
for	 Â  efficiency.	 Â  Once	 Â  we	 Â  had	 Â  trained	 Â  a	 Â  set	 Â  of	 Â  feature	 Â  weights,	 Â  we	 Â  could	 Â  then	 Â  generate	 Â  the	 Â  R-Â­â€
Score	 Â prediction	 Â 
Model	 Â 1:	 Â Linear	 Â Regression	 Â 
	 Â R-Â­â€Score	 Â =	 Â ğœƒ0	 Â +	 Â ğœƒ1	 Â *	 Â F1	 Â +	 Â ğœƒ2 âˆ— ğ¹2	 Â +	 Â â€¦	 Â +	 Â ğœƒğ‘› âˆ— ğ¹ğ‘› ,	 Â where	 Â ğœƒğ‘– 	 Â are	 Â the	 Â weights,	 Â ğ¹ğ‘– 	 Â are	 Â the	 Â features	 Â 
and	 Â n	 Â is	 Â the	 Â number	 Â of	 Â features	 Â 
	 Â To	 Â  measure	 Â  the	 Â  â€œgoodnessâ€	 Â  of	 Â  our	 Â  results,	 Â  we	 Â  looked	 Â  at	 Â  the	 Â  correlation	 Â  between	 Â  our	 Â 
predicted	 Â metric	 Â values	 Â and	 Â  the	 Â actual	 Â metric	 Â values,	 Â as	 Â was	 Â done	 Â  in	 Â other	 Â papers	 Â [1][2].	 Â As	 Â 
alternative	 Â  measures	 Â  to	 Â  interpret	 Â  our	 Â  results,	 Â  we	 Â  also	 Â  considered	 Â  other	 Â  metrics	 Â  such	 Â  as	 Â 
mean	 Â  absolute	 Â  percentage	 Â  error	 Â  (MAPE)	 Â  and	 Â  symmetric	 Â  mean	 Â  absolute	 Â  percentage	 Â  error	 Â 
(SMAPE).	 Â 
	 Â MAPE	 Â  is	 Â  not	 Â  the	 Â  best	 Â  metric	 Â  for	 Â  our	 Â  work	 Â  because	 Â  the	 Â  error	 Â  is	 Â  unbounded	 Â  metric	 Â  value	 Â 
(Time)	 Â  of	 Â  1000	 Â  sec	 Â  for	 Â  a	 Â  given	 Â  surgery	 Â  exercise	 Â  that	 Â  was	 Â  performed	 Â  in	 Â  100	 Â  sec,	 Â  then	 Â  error	 Â 
would	 Â  be	 Â  900%,	 Â  skewing	 Â  any	 Â  average	 Â  we	 Â  would	 Â  take	 Â  over	 Â  all	 Â  test	 Â  examples.	 Â  In	 Â 
compensation	 Â  to	 Â  this,	 Â  we	 Â  also	 Â  tried	 Â  SMAPE,	 Â  which	 Â  returns	 Â  error	 Â  values	 Â  from	 Â  0	 Â  to	 Â  100%.	 Â 
However	 Â neither	 Â metric	 Â gave	 Â consistent,	 Â explainable	 Â results.	 Â 
Below	 Â  are	 Â  the	 Â  correlation	 Â  results	 Â  we	 Â  found	 Â  for	 Â  each	 Â  of	 Â  our	 Â  feature	 Â  sets,	 Â  using	 Â  90%	 Â  of	 Â  our	 Â 
data	 Â in	 Â training	 Â 
	 Â In	 Â  our	 Â  first	 Â model,	 Â  we	 Â  used	 Â  a	 Â  standard	 Â  least-Â­â€squares	 Â  linear	 Â  regression.	 Â  To	 Â  do	 Â  this,	 Â  we	 Â  used	 Â 
stochastic	 Â gradient	 Â descent,	 Â which	 Â we	 Â  implemented	 Â  in	 Â C	 Â  for	 Â efficiency.	 Â Once	 Â we	 Â had	 Â  trained	 Â 
a	 Â set	 Â of	 Â feature	 Â weights,	 Â we	 Â could	 Â then	 Â generate	 Â R-Â­â€Score	 Â predictions	 Â as	 Â follows:	 Â 
	 Â 	 Â 
Sentiment	 Â Features	 Â 
Complex	 Â Features	 Â 
Simple	 Â Features	 Â 
Test	 Â Data	 Â Set	 Â 
0.7198	 Â correlation	 Â 
0.7428	 Â correlation	 Â 
0.7506	 Â correlation	 Â 
Training	 Â Data	 Â Set	 Â 
0.7291	 Â correlation	 Â 
0.8120	 Â correlation	 Â 
0.8139	 Â correlation	 Â 
	 Â 

	 Â 

	 Â 	 Â 
Predicted	 Â and	 Â Actual	 Â R-Â­â€Score	 Â (LogX-Â­â€LogY	 Â Scatter)	 Â 
	 Â 
Model	 Â 2:	 Â Classification	 Â by	 Â Logistic	 Â Regression	 Â 
As a second model, we also tried classification by standard L1-regularized logistic regression. We 
chose  this  method  because  it  generated  a  multi-class  model  with  linear  weights,  most  directly 
comparable  to  the  feature  weights  given  by  linear  regression.  To  define  our  classes,  we  drew  a 
histogram of surgery exercise to create 5 different buckets for prediction as shown below: 
 Buckets	 Â 
Bucket	 Â 1	 Â 
Bucket	 Â 2	 Â 
Bucket	 Â 3	 Â 
Bucket	 Â 4	 Â 
Bucket	 Â 5	 Â 
The  first  bucket  includes  the  lowest  20%  of  the R-Score  distribution  and  the  last  bucket  includes 
R-Â­â€Score	 Â 
69.6	 Â 
29.2	 Â to	 Â 69.6	 Â 
11.2	 Â to	 Â 29.2	 Â 
1.4	 Â to	 Â 11.1	 Â 
0	 Â to	 Â 1.4	 Â 
the highest 20%. 
 
The  procedure  for  using  logistic  regression  was  fairly  similar  to  that  of  linear  regression;  the 
difference  being  that  we  now  use  labeled  buckets  as  our  y-values  (instead  of  real-valued  R-
of classification was not the right approach to the problem.	 Â 
scores)  and  pass  the  data  to  liblinear  to  build  the  model  for  classification.  This  model  gave  the 
	 Â 	 Â 
following accuracy results on our 10% test set: 
Simple	 Â Features	 Â 
Complex	 Â Features	 Â 
Sentiment	 Â Features	 Â 
In general, none of  these accuracy figures were as high as we had hoped,  indicating  that  this kind 
49.40%	 Â 
50.14%	 Â 
49.05%	 Â 
Test	 Â Data	 Â Set	 Â 
	 Â 	 Â 
Having	 Â  developed	 Â  these	 Â  different	 Â  models,	 Â  we	 Â  need	 Â  some	 Â  way	 Â  of	 Â  comparing	 Â  these	 Â  results.	 Â 
For	 Â this	 Â project,	 Â I	 Â implemented	 Â two	 Â methods,	 Â we	 Â map	 Â the	 Â results	 Â from	 Â linear	 Â regression	 Â into	 Â 
the	 Â  five	 Â  bucket	 Â  classes	 Â  from	 Â  logistic	 Â  regression.	 Â  So,	 Â  in	 Â  order	 Â  to	 Â  do	 Â  this,	 Â  we	 Â  take	 Â  the	 Â  real-Â­â€
Final	 Â Comparison:	 Â 
valued	 Â  outputs	 Â  from	 Â  our	 Â  linear	 Â  regression	 Â  model,	 Â  assign	 Â  labels	 Â  to	 Â  them	 Â  according	 Â  to	 Â  the	 Â 
buckets	 Â  into	 Â  which	 Â  they	 Â  fall,	 Â  and	 Â  check	 Â  these	 Â  corresponding	 Â  values	 Â  in	 Â  the	 Â  same	 Â  bucket	 Â  as	 Â 
those	 Â of	 Â the	 Â actual	 Â R-Â­â€Score.	 Â 
	 Â 	 Â 
Sentiment	 Â Features	 Â 
Complex	 Â Features	 Â 
Simple	 Â Features	 Â 
Test	 Â Data	 Â Set	 Â 
49.56%	 Â 
45.14%	 Â 
41.04%	 Â 

	 Â These	 Â numbers	 Â decrease	 Â with	 Â additional	 Â features,	 Â likely	 Â because	 Â of	 Â increased	 Â variance	 Â (that	 Â 
is,	 Â some	 Â over-Â­â€fitting	 Â on	 Â  the	 Â  training	 Â set-Â­â€-Â­â€	 Â  further	 Â discussion	 Â of	 Â  this	 Â  in	 Â  the	 Â  following	 Â section).	 Â 
However,	 Â  all	 Â  are	 Â  roughly	 Â  comparable	 Â  to	 Â  the	 Â  49%	 Â  accuracy	 Â  achieved	 Â  by	 Â  logistic	 Â  regression	 Â 
on	 Â the	 Â classification	 Â problem,	 Â showing	 Â that	 Â linear	 Â regression	 Â is	 Â almost	 Â as	 Â good	 Â at	 Â the	 Â task	 Â of	 Â 
classification	 Â as	 Â logistic	 Â regression,	 Â the	 Â algorithm	 Â dedicated	 Â to	 Â classification.	 Â 	 Â 
In	 Â the	 Â second	 Â method,	 Â instead	 Â of	 Â mapping	 Â from	 Â real	 Â values	 Â to	 Â buckets,	 Â we	 Â map	 Â from	 Â our	 Â five	 Â 
buckets	 Â  to	 Â  real	 Â  values.	 Â  To	 Â  do	 Â  this,	 Â  we	 Â  first	 Â  find	 Â  the	 Â  average	 Â  R-Â­â€scores	 Â  classified	 Â  into	 Â  each	 Â 
bucket	 Â  in	 Â  logistic	 Â  regression.	 Â  Then,	 Â  instead	 Â  of	 Â  generating	 Â  class	 Â  labels	 Â  from	 Â  logistic	 Â 
regression,	 Â  we	 Â  can	 Â  use	 Â  the	 Â  corresponding	 Â  averages	 Â  instead,	 Â  giving	 Â  us	 Â  real-Â­â€valued	 Â  output	 Â 
from	 Â the	 Â classifier.	 Â Thus	 Â the	 Â resulting	 Â correlation	 Â scores	 Â are	 Â as	 Â follows:	 Â 
	 Â 	 Â 
Sentiment	 Â Features	 Â 
Complex	 Â Features	 Â 
Simple	 Â Features	 Â 
Test	 Â Data	 Â Set	 Â 
0.5217	 Â correlation	 Â 
0.5675	 Â correlation	 Â 
0.5601	 Â correlation	 Â 
	 Â None	 Â of	 Â these	 Â approach	 Â the	 Â 0.75	 Â range	 Â of	 Â correlation	 Â seen	 Â with	 Â  linear	 Â regression,	 Â much	 Â  less	 Â 
the	 Â  0.63	 Â  baseline	 Â  correlation	 Â  using	 Â  a	 Â  simulation	 Â  exerciseâ€™s	 Â  time	 Â  taken	 Â  alone.	 Â  Much	 Â  of	 Â  this	 Â 
has	 Â  to	 Â  do	 Â with	 Â  the	 Â  fact	 Â  that	 Â  logistic	 Â  regression	 Â  can	 Â  only	 Â  generate	 Â  one	 Â  of	 Â  five	 Â  distinct	 Â  values,	 Â 
so	 Â we	 Â  thought	 Â we	 Â might	 Â experiment	 Â with	 Â different	 Â number	 Â of	 Â buckets.	 Â Our	 Â expectation	 Â was	 Â 
that	 Â  accuracy	 Â  would	 Â  consistently	 Â  decrease	 Â  as	 Â  number	 Â  of	 Â  buckets	 Â  increased,	 Â  but	 Â  that	 Â 
correlation	 Â  would	 Â  have	 Â  some	 Â  optimal	 Â  point	 Â  where	 Â  the	 Â  (positive)	 Â  granularity	 Â  of	 Â  having	 Â 
smaller-Â­â€ranged	 Â buckets	 Â balanced	 Â with	 Â  the	 Â (negative)	 Â  trend	 Â  toward	 Â  fewer	 Â  training	 Â examples	 Â 
per	 Â bucket.	 Â We	 Â were	 Â  surprised	 Â  to	 Â  find	 Â  that	 Â while	 Â  accuracy	 Â decreased,	 Â  correlation	 Â  remained	 Â 
fairly	 Â constant,	 Â as	 Â shown	 Â in	 Â the	 Â following	 Â figure:	 Â 
	 Â 

	 Â 	 Â 	 Â 	 Â 

	 Â 

It	 Â  appears	 Â  that,	 Â  in	 Â  terms	 Â  of	 Â  the	 Â  correlation	 Â  measure,	 Â  having	 Â  fewer	 Â  training	 Â  examples	 Â  per	 Â 
bucket	 Â was	 Â evenly	 Â offset	 Â by	 Â the	 Â greater	 Â granularity	 Â of	 Â having	 Â smaller-Â­â€ranged	 Â buckets.	 Â 
We	 Â  framed	 Â  this	 Â  problem	 Â  as	 Â  both	 Â  a	 Â  regression	 Â  and	 Â  classification	 Â  problem	 Â  because	 Â  we	 Â  were	 Â 
not	 Â  sure	 Â  which	 Â  would	 Â  provide	 Â  a	 Â  better	 Â  result;	 Â  as	 Â  such,	 Â  we	 Â  implemented	 Â  both	 Â  and	 Â  devised	 Â 
	 Â 
methods	 Â to	 Â compare	 Â them.	 Â In	 Â general,	 Â we	 Â  found	 Â that	 Â  linear	 Â regression	 Â works	 Â almost	 Â as	 Â well	 Â 
Conclusion	 Â 
as	 Â  logistic	 Â  regression	 Â  for	 Â  classification	 Â  on	 Â  our	 Â  data,	 Â  while	 Â  having	 Â  a	 Â much	 Â  better	 Â  correlation	 Â 
with	 Â  the	 Â  actual	 Â  gross	 Â  revenues.	 Â  In	 Â  general,	 Â  we	 Â  found	 Â  that	 Â  the	 Â  features	 Â  we	 Â  used	 Â  (simple	 Â 
numeric,	 Â  text,	 Â  and	 Â  sentiment	 Â  features)	 Â  were	 Â  insufficient	 Â  to	 Â  make	 Â  strong	 Â  predictions	 Â  of	 Â  R-Â­â€
Score.	 Â  For	 Â  future	 Â work,	 Â  besides	 Â  using	 Â  different	 Â  feature	 Â  sets,	 Â we	 Â might	 Â  consider	 Â  using	 Â  better	 Â 
regularization	 Â  on	 Â  linear	 Â  regression	 Â  in	 Â  order	 Â  to	 Â  provide	 Â  a	 Â  more	 Â  rigorous	 Â  safeguard	 Â  against	 Â 
high-Â­â€variance	 Â  models,	 Â  as	 Â  we	 Â  consistently	 Â  observed	 Â  decreases	 Â  in	 Â  linear	 Â  regressionâ€™s	 Â  test	 Â 
accuracy	 Â with	 Â increasing	 Â numbers	 Â of	 Â features.	 Â 	 Â 
	 Â Another,	 Â  fundamentally	 Â  different,	 Â  data	 Â  set	 Â  that	 Â  might	 Â  be	 Â  useful	 Â  in	 Â  predicting	 Â  a	 Â  simulatorâ€™s	 Â 
validity	 Â would	 Â be	 Â social	 Â graph	 Â data:	 Â using	 Â such	 Â data,	 Â we	 Â could	 Â analyze	 Â  the	 Â characteristics	 Â of	 Â 
how	 Â  a	 Â  traineeâ€™s	 Â  performance	 Â  propagates	 Â  through	 Â  real	 Â  surgery,	 Â  as	 Â  well	 Â  as	 Â  characteristics	 Â  of	 Â 
the	 Â  propagation	 Â  tree,	 Â  such	 Â  as	 Â  its	 Â  speed	 Â  and	 Â  extent	 Â  over	 Â  time.	 Â  The	 Â  propagation	 Â  speed	 Â  of	 Â  a	 Â 
trainee	 Â  would	 Â  represent	 Â  performance	 Â  expectation	 Â  to	 Â  see	 Â  that	 Â  a	 Â  simulation	 Â  exercise,	 Â  which	 Â 
we	 Â expect	 Â will	 Â be	 Â directly	 Â related	 Â to	 Â its	 Â R-Â­â€score.	 Â 
	 Â Moreover,	 Â  we	 Â  looked	 Â  at	 Â  our	 Â  feature	 Â  weights	 Â  for	 Â  text-Â­â€based	 Â  features,	 Â  and	 Â  from	 Â  them	 Â 
extracted	 Â  the	 Â  highest-Â­â€	 Â  and	 Â  lowest-Â­â€weighted	 Â  features	 Â  in	 Â  right	 Â  hand	 Â  movement,	 Â  left	 Â  hand	 Â 
movement,	 Â and	 Â clutch	 Â pedal	 Â usage,	 Â camera	 Â usage.	 Â 
	 Â 
	 Â 
1)  Stegemann	 Â AP,	 Â Kesavadas	 Â T,	 Â Rehman	 Â  S,	 Â  Sharif	 Â M,	 Â Rao	 Â A,	 Â DuPont	 Â N,	 Â  Shi	 Â Y,	 Â Wilding,G,	 Â 
Hassett	 Â  J,	 Â  and	 Â  Guru	 Â  K,	 Â  "Development,	 Â  Implementation	 Â  and	 Â  Validation	 Â  of	 Â  a	 Â 
References	 Â 
Simulation-Â­â€Based	 Â  Curriculum	 Â  for	 Â  Robot-Â­â€Assisted	 Â  Surgery"	 Â  Presented	 Â  at	 Â  the	 Â  AUA	 Â 
poster	 Â session,	 Â May	 Â 19-Â­â€23,	 Â 2012	 Â Atlanta,	 Â GA.	 Â 
2)  Kesavadas	 Â  T,	 Â  Stegemann	 Â  A,	 Â  Sathyaseelan,	 Â  G,	 Â  Chowriappa	 Â  A,	 Â  Srimathveeravalli	 Â  G,	 Â 
Seixas-Â­â€Mikelus	 Â  S,	 Â  Chandrasekhar	 Â  R,	 Â  Wilding	 Â  G,	 Â  and	 Â  Guru	 Â  K.	 Â  "Validation	 Â  of	 Â  Robotic	 Â 
Surgery	 Â Simulator	 Â (RoSS)",	 Â Stud	 Â Health	 Â Technol	 Â Inform.	 Â 2011;163:274-Â­â€6.	 Â 
3)  Zorn	 Â K,	 Â and	 Â Gautam	 Â G,	 Â  "Training,	 Â Credentialing,	 Â and	 Â Hospital	 Â Privileging	 Â  for	 Â Robotic	 Â 
Urological	 Â Surgery"	 Â In	 Â Robotics	 Â in	 Â Genitourinary	 Â Surgery	 Â 2011,	 Â Part	 Â 2,	 Â PP	 Â 169-Â­â€181.	 Â 
4)  Su	 Â D,	 Â and	 Â Barone	 Â J	 Â "Initial	 Â Experience	 Â with	 Â the	 Â ROSS	 Â Robotic	 Â Simulator	 Â in	 Â Residency	 Â 
Training"	 Â moderated	 Â poster,	 Â AUA	 Â 2011	 Â 
5)  Seixas-Â­â€Mikelus	 Â SA,	 Â Stegemann	 Â AP,	 Â Kesavadas	 Â T,	 Â Srimathveeravalli	 Â G,	 Â Sathyaseelan	 Â G,	 Â 
Chandrasekhar	 Â  R,	 Â  Wilding	 Â  GE,	 Â  Peabody	 Â  JO,	 Â  and	 Â  Guru	 Â  KA.	 Â  "Content	 Â  validation	 Â  of	 Â  a	 Â 
novel	 Â  robotic	 Â  surgical	 Â  simulator",	 Â  British	 Â 
Journal	 Â  of	 Â  Urology,	 Â  2011	 Â  2011	 Â 
Apr;107(7):1130-Â­â€5	 Â 

